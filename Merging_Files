####Loading needed packages####
library(tidyverse)
library(mice)
library(lubridate)
library(Hmisc)
library(stringr)
library(readr)
library(plyr)
library(dplyr)

####Reading in original data files####
device_ids_matched <- read_csv("List of 23038 device ids that match.csv")
#Note this file was added to google drive PREDICT 498/Jordan Additional Data Files
device_ids_train <- read_csv("device ids for training set")
#Note this file was added to google drive PREDICT 498/Jordan Additional Data Files
device_ids_test <- read_csv("device ids for test set")
#Note this file was added to google drive PREDICT 498/Jordan Additional Data Files
gender_age_train <- read_csv("Data/gender_age_train.csv")
app_labels <- read_csv("Data/app_labels.csv")
events <- read_csv("Data/events.csv")
label_categories <- read_csv("Data/label_categories_big2.csv")
#Note this file was modified by CJ and pulled from google drive
phone_brand_device_model <- read_csv("Data/Brand_Find_Replace2.csv") 
#Note this file was modififed by CJ and pulled from google drive
app_events <- read_csv("Data/app_events.csv")
#label_categories <- read_csv("Data/label_categories.csv")
#phone_brand_device_model <- read_csv("Data/phone_brand_device_model.csv") 
#NOTE: Reading in the labels and brands modefied by CJ, so the raw data is not needed
#sample_submission <- read_csv("Data/sample_submission.csv")
#NOTE: Don't need the sample submission
#gender_age_test <- read_csv("Data/gender_age_test.csv")
#NOTE: Don't need the test set

####Merging the data into one file####
#     File to predict age/gender     #
####Merge gender_age_train and phone_brand_device_model into new df named 'merge_data_1'####
merged_data_1 <-
gender_age_train %>%
  left_join(phone_brand_device_model, by = "device_id")%>% #Merging the data
  filter(device_id %in% device_ids_matched$device_id) #Removing unnecessary device_ids
#NOTE: The merged file returns more observations than the original gender_age_train set indicating duplicates

#Identifying duplicates where the entire row is a duplicate (every column matches)
merged_data_1$duplicate <- duplicated(merged_data_1) | duplicated(merged_data_1, fromLast = TRUE)

#Counting the number of duplicate rows
plyr::count(merged_data_1, "duplicate")
#There are 386 duplicate rows

#Creating a flag variable to identify the cases that were duplicates after deduping
merged_data_1$device_model_duplicate_flag <- 0
merged_data_1$device_model_duplicate_flag[merged_data_1$duplicate == "TRUE"] <- 1
plyr::count(merged_data_1, "device_model_duplicate_flag")

#Removing duplicates where the entire row is a duplicate (every column matches)
#Also dropping the duplicate column as it is no longer needed
#By remove, I mean leaving only 1 of the duplicated rows in the dataset
merged_data_1 <- merged_data_1[!duplicated(merged_data_1), ] %>%
  select(-duplicate)
#NOTE: There is one duplicate observation where the entire row isn't duplicated

#Identifying the duplicate where only device_id is a duplicated
merged_data_1$duplicate_device_id <- duplicated(merged_data_1$device_id) | duplicated(merged_data_1$device_id, fromLast = TRUE)

#Counting the number of duplicate rows for just device_id
plyr::count(merged_data_1, "duplicate_device_id")
#Confirms 2 rows with same device_id
#NOTE: This obervation has the same device_id, but different device_model and phone_brand

#Entirely removing the device_id that has inconsistent data
#By remove, I mean removing both observations and eliminating this device_id entirely
merged_data_1 <- merged_data_1 %>%
  filter(duplicate_device_id == "FALSE") %>%
  select(-duplicate_device_id)

#Visually inspecting observations
head(merged_data_1)
#summarizing each variable in the df
summary(merged_data_1)
#NOTE: gender, group, phone_brand, and device_model are being read as large character fields when in reality these could be factors

#Changing gender, group, phone_brand, and device_model into factor types
merged_data_1$gender <- as.factor(merged_data_1$gender)
merged_data_1$group <- as.factor(merged_data_1$group)
merged_data_1$phone_brand <- as.factor(merged_data_1$phone_brand)
merged_data_1$device_model <- as.factor(merged_data_1$device_model)
merged_data_1$device_model_duplicate_flag <- as.factor(merged_data_1$device_model_duplicate_flag)

#Confirming types and verified that there are no NA values in the merged set
summary(merged_data_1)
merged_data_1_missing_pattern <- as.data.frame(md.pattern(merged_data_1))

#Removing the phone_brand_device_model df and the gender_age_train df from the environment as they are now merged into the new df
rm(phone_brand_device_model)
rm(gender_age_train)
rm(merged_data_1_missing_pattern)


####Merge events and app_events into new df named 'merged_data_2'####
#Because of the size of these files it is easier to check or duplicates prior to merge
#Checking if there are any complete (full row) duplicates in the events data
events$duplicate <- duplicated(events) | duplicated(events, fromLast = TRUE)
plyr::count(events, "duplicate")
#There are no complete duplicates

#Checking if there are any event_id only duplicates in the events data
events$duplicate_event_id <- duplicated(events$event_id) | duplicated(events$event_id, fromLast = TRUE)
plyr::count(events, "duplicate_event_id")
#There are no duplicate event_ids in the events data

#Filtering events to only the necessary device_ids
events <- events %>%
  filter(device_id %in% device_ids_matched$device_id)

#Removing the variables (duplicate and duplicate_event_id) used to identify duplicates from events data
events <- events %>%
  select(-duplicate)%>%
  select(-duplicate_event_id)

head(events)

#Checking if there are any complete (full row) duplicates in the app_events data
app_events$duplicate <- duplicated(app_events) | duplicated(app_events, fromLast = TRUE)
plyr::count(app_events, "duplicate")
#Indicates that there are 23,820 rows that have complete duplicates

#Creating a new dataset of only duplicates to visually verify the duplicates
app_events_duplicates <- app_events %>%
  filter(duplicate == "TRUE")
#Quick visual look and it does appear that these are all full duplicates (across all rows)

#Deleting the df of only duplicates that was used to visually check for full duplicates
rm(app_events_duplicates) 

#Creating a flag variable to identify which obervations were duplicates after deduping
app_events$app_event_full_duplicate_flag <- 0
app_events$app_event_full_duplicate_flag[app_events$duplicate == "TRUE"] <- 1
plyr::count(app_events, "app_event_full_duplicate_flag")

#Removing the complete (full row) duplicates
#By remove, I mean that I leave only 1 of the matching observations the df
#Also dropping the duplicate column as it is no longer needed
app_events <- app_events[!duplicated(app_events), ] %>%
  select(-duplicate)

#Visual observation to assess the first few rows of data
head(app_events)

#For the app_events data it would make sense to have duplicate event_ids and duplicate app_ids, but duplicate combinations shouldn't exist
#Checking if there are any event_id and app_id combination duplicates in the cleaner app_events data
app_events$duplicate <- duplicated(app_events[,1:2]) | duplicated(app_events[,1:2], fromLast = TRUE)
plyr::count(app_events, "duplicate")
#There are 2,946 duplicates rows of event_id and app_id

#Creating a new dataset of only duplicates to visually verify the duplicates
app_events_duplicates <- app_events %>%
  filter(duplicate == "TRUE")
#Quick visual look and it does appear that these are duplicates with multiple rows with thes same event_id and app_id 
#Duplicates have the same event_id and app_id, but each has one row where is_active is 1 and one row where is_active is 0

#Deleting the df of only duplicates that was used to visually check for full duplicates
rm(app_events_duplicates)

#Creating a flag variable so that these duplicates can be identified after deduping
app_events$is_active_duplicate_flag <- 0
app_events$is_active_duplicate_flag[app_events$duplicate == "TRUE"] <- 1
head(app_events)

#Removing the partial (app_id and event_id combination) duplicates
#By remove, I mean that I leave only 1 of the matching observations the df
#I am forcing it to choose the observation that has is_active as 1
app_events <- app_events%>%
  filter(duplicate == "FALSE" | duplicate == "TRUE" & is_active == 1)

#Confirming only half of the duplicates remain
plyr::count(app_events, "duplicate")

#Dropping the duplicate column as it is no longer needed
app_events <- app_events%>%
  select(-duplicate)

#Merging the events and app_events dfs into a new df named merged_data_2
#Using a full_join, so all observations should remain
merged_data_2 <-
  events %>%
  left_join(app_events, by = "event_id") 

#Getting summary of the new combined dataset
summary(merged_data_2)


n_distinct(merged_data_2$event_id)
#1,212,306 unique event_id as expected
summary(plyr::count(merged_data_2$event_id))

n_distinct(merged_data_2$device_id)
#22,402 unique device_ids - means that there will be missing when merged to merged_data_1
summary(plyr::count(merged_data_2$device_id))
summary(merged_data_2)

#Removing the app_events and events dfs from the environment as they are now merged
rm(app_events)
rm(events)

###Merge app_labels and label_categories into new df named 'merge_data_3'###
#Checking to see if there are full duplicates in the label_categories df
label_categories$duplicate <- duplicated(label_categories) | duplicated(label_categories, fromLast = TRUE)
plyr::count(label_categories, "duplicate")
#No duplicates

#Checking to see if label_id within label_categories alone is duplicated
label_categories$duplicate <- duplicated(label_categories$label_id) | duplicated(label_categories$label_id, fromLast = TRUE)
plyr::count(label_categories, "duplicate")
#No duplicates

#Removing duplicate column as it is no longer needed
label_categories <- label_categories%>%
  select(-duplicate)

#Checking to see if there are any full duplicates in the app_labels df
app_labels$duplicate <- duplicated(app_labels) | duplicated(app_labels, fromLast = TRUE)
plyr::count(app_labels, "duplicate")
#There are 32,134 rows that are complete matches with other rows

#Removing the duplicate rows in the app_labels df
#By remove, I mean keeping only 1 row when there are multiple rows that are identical
app_labels <- app_labels[!duplicated(app_labels), ] %>%
  select(-duplicate)

#Checking to see if app_id within app_labels along is duplicated
app_labels$duplicate <- duplicated(app_labels$app_id) | duplicated(app_labels$app_id, fromLast = TRUE)
plyr::count(app_labels, "duplicate")
#Yes, most are duplicated which indicates that most app_ids have multiple label_ids (meaning apps have multple category assignments)

app_labels <- app_labels%>%
  select(-duplicate)

merged_data_3 <-
  app_labels %>%
  left_join(label_categories, by = "label_id") 
#NOTE: there are 423 more observations post merge compared to the n from app_labels prior to merge
#This was found by doing a full_join
#This indicates that there are 423 labels that didn't match to an app
#We don't care about labels that aren't associated with an app, so a left_join was used

summary(merged_data_3)

#the category variable is being stored as a large character, but should be a factor
merged_data_3$category <- as.factor(merged_data_3$category)

#removing the app_labels and label_categories dfs from the environment because they are now merged
rm(app_labels)
rm(label_categories)

###Merging merged_data_1 and merged_data_2 into a new df named 'merged_data_4###
#left_join was used because we only want more information on devices also found in the training set
merged_data_4 <- merged_data_1%>%
  left_join(merged_data_2, by = "device_id")

summary(merged_data_4)
n_distinct(merged_data_4$device_id) #23,038 as expected

###Merging merged_data_4 and merged_data_3 into new df named 'final_merged_data;###
final_merged_data <- merged_data_4 %>%
  left_join(merged_data_3, by = "app_id")

summary(final_merged_data)
n_distinct(final_merged_data$device_id) #23,038 as expected
head(final_merged_data)

rm(merged_data_2)
rm(merged_data_3)
rm(merged_data_4)
rm(device_ids_matched)

###Writing to csv file (note hashed out because I don't want to rewrite)
#write_csv(final_merged_data, "merged_data_Jordan.csv")

#Reducing final_merged_data to only device ids in the training set#
final_merged_data_train <- final_merged_data %>%
  filter(device_id %in% device_ids_train$device_id)
n_distinct(final_merged_data_train$device_id) #17,278 as expected

summary(final_merged_data_train)

#Creating each column for the final training set
by_device_id_train_counts_1 <- final_merged_data_train %>%
  group_by(
    device_id
  ) %>%
  dplyr::summarize(
    event_count = n_distinct(event_id, na.rm = TRUE), 
    app_id_unique_count = n_distinct(app_id, na.rm = TRUE), 
    is_active_sum = sum(is_active, na.rm = TRUE),
    label_id_unique_count = n_distinct(label_id, na.rm = TRUE),
    timestamp_unique_count = n_distinct(timestamp, na.rm = TRUE),
    earilest_timestamp = min(timestamp),
    latest_timestamp = max(timestamp),
    days_between_first_and_last_timestamp = difftime(max(timestamp, na.rm = TRUE), min(timestamp, na.rm = TRUE), units = "days"),
    hours_between_first_and_last_timestamp = difftime(max(timestamp, na.rm = TRUE), min(timestamp, na.rm = TRUE), units = "hours"),
    big_category_unique_count = n_distinct(big_category, na.rm = TRUE)
  )

by_device_id_train_counts_2 <- final_merged_data_train %>%
  group_by(
    device_id,
    big_category
  ) %>%
  dplyr::summarize(
    category_count = n()
  ) %>%
  filter(
    !is.na(big_category)
  ) %>%
  spread(
    big_category,
    category_count,
    fill = 0
  )

names(by_device_id_train_counts_2)[2:ncol(by_device_id_train_counts_2)] <- str_c(
  'bc_',
  str_replace_all(
    names(by_device_id_train_counts_2)[2:ncol(by_device_id_train_counts_2 )],
    ' ',
    ''
  )
)

#merging counts together and adding demographics back into training set
by_device_id_final_train <- left_join(by_device_id_train_counts_1, by_device_id_train_counts_2, by = 'device_id') %>%
  left_join(merged_data_1, by = "device_id")

rm(by_device_id_train_counts_1)
rm(by_device_id_train_counts_2)
rm(final_merged_data_train)

#writing the final train dataset to a csv
write_csv(by_device_id_final_train, "by_device_id_final_train.csv")

#Reducing final_merged_data to only device ids in the test set#
final_merged_data_test <- final_merged_data %>%
  filter(!device_id %in% device_ids_train$device_id)
n_distinct(final_merged_data_test$device_id) #5,760 as expected

#Creating each column for the final test set
by_device_id_test_counts_1 <- final_merged_data_test %>%
  group_by(
    device_id
  ) %>%
  dplyr::summarize(
    event_count = n_distinct(event_id, na.rm = TRUE), 
    app_id_unique_count = n_distinct(app_id, na.rm = TRUE), 
    is_active_sum = sum(is_active, na.rm = TRUE),
    label_id_unique_count = n_distinct(label_id, na.rm = TRUE),
    timestamp_unique_count = n_distinct(timestamp, na.rm = TRUE),
    earilest_timestamp = min(timestamp),
    latest_timestamp = max(timestamp),
    days_between_first_and_last_timestamp = difftime(max(timestamp, na.rm = TRUE), min(timestamp, na.rm = TRUE), units = "days"),
    hours_between_first_and_last_timestamp = difftime(max(timestamp, na.rm = TRUE), min(timestamp, na.rm = TRUE), units = "hours"),
    big_category_unique_count = n_distinct(big_category, na.rm = TRUE)
  )

by_device_id_test_counts_2 <- final_merged_data_test %>%
  group_by(
    device_id,
    big_category
  ) %>%
  dplyr::summarize(
    category_count = n()
  ) %>%
  filter(
    !is.na(big_category)
  ) %>%
  spread(
    big_category,
    category_count,
    fill = 0
  )

names(by_device_id_test_counts_2)[2:ncol(by_device_id_test_counts_2)] <- str_c(
  'bc_',
  str_replace_all(
    names(by_device_id_test_counts_2)[2:ncol(by_device_id_test_counts_2 )],
    ' ',
    ''
  )
)

#merging counts together and adding demographics back into training set
by_device_id_final_test <- left_join(by_device_id_test_counts_1, by_device_id_test_counts_2, by = 'device_id') %>%
  left_join(merged_data_1, by = "device_id")

#writing the final train dataset to a csv
write_csv(by_device_id_final_test, "by_device_id_final_test.csv")

rm(by_device_id_test_counts_1)
rm(by_device_id_test_counts_2)
rm(final_merged_data_test)
rm(device_ids_test)
rm(device_ids_train)

#write_csv(test, "sample_demographic_file.csv")
#device_id_matched <- as.data.frame(test$device_id)
#write_csv(device_id_matched, "List of 23038 device ids that match")

#set.seed(1)
#device_ids_train <- sample_frac(device_ids_matched, size = 0.75)
#device_ids_test <- device_ids_matched %>%
#  filter(!device_id %in% device_ids_train$device_id)

#write_csv(device_ids_train, "device ids for training set")
#write.csv(device_ids_test, "device ids for test set")
